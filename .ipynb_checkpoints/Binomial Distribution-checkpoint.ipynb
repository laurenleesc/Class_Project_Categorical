{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "#from math import exp,log\n",
    "from numpy import array, exp, log\n",
    "from sklearn.linear_model import LogisticRegression    #this is to compare our answers to..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is Lauren's attempt to create the loglikelhood, gradient matrix and hessian matrix for the sigmoid link function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('bernoulli_X.npy')\n",
    "Beta=np.load('bernoulli_betas.npy')\n",
    "Y=np.load('bernoulli_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I simulated 30 observations using Shafi's code\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorized the calculation instead of a for-loop\n",
    "def LogLikelihoodBinomial(x, start_point_betas, y):\n",
    "    beta=start_point_betas.reshape(len(start_point_betas),1)\n",
    "    mu=x.T*beta\n",
    "    #see page 15 in Dr. VanBrackle's notes\n",
    "    L_matrix = y*mu - log(1+exp(mu))\n",
    "    L = np.sum(y*mu) - np.sum(log(1+exp(mu)))\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-306.8351139855476"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogLikelihoodBinomial(X,Beta,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorized the calculation instead of a for-loop\n",
    "def gradient(x, start_point_betas, y):\n",
    "    mu = x.T*start_point_betas\n",
    "    #see page 16 in Dr. VanBrackle's notes...this is the derivative of the LL wrt vector of betas\n",
    "    gradient = y.T.dot(x) - (1/(1+exp(-mu))).T*x\n",
    "    #check=np.sum(y.T.dot(x)) - np.sum((1/(1+exp(-mu))).T*x)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_matrix=gradient(X,Beta,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian(x, start_point_betas, y):\n",
    "    mu = x.T*start_point_betas\n",
    "    #https://www.derivative-calculator.net/\n",
    "    #second derivative of LL wrt Betas\n",
    "    hessian = ((x*exp(-mu).T)*x) / ((1+exp(-mu))*(1+exp(-mu))).T\n",
    "    #hessian = ((1+exp(-mu))*(1+exp(-mu)))\n",
    "    #check=np.sum(y.T.dot(x)) - np.sum((1/(1+exp(-mu))).T*x)\n",
    "    return hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian_matrix=hessian(X,Beta,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessian_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________\n",
    "Below is Lauren's attempt at gradient descent.  Source: https://beckernick.github.io/logistic-regression-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(scores):\n",
    "    return 1 / (1 + np.exp(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_est(features, target, num_steps, learning_rate, add_intercept = False):\n",
    "    if add_intercept:\n",
    "        intercept = np.ones((features.shape[0], 1))\n",
    "        features = np.hstack((intercept, features))\n",
    "    \n",
    "    #here is our start point, all zeroes\n",
    "    weights = np.zeros(features.shape[1])\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        scores = np.dot(features, weights)\n",
    "        predictions = sigmoid(scores)\n",
    "\n",
    "        # Update weights with gradient\n",
    "        output_error_signal = target - predictions\n",
    "        \n",
    "        gradient = np.dot(features.T, output_error_signal)\n",
    "        weights += learning_rate * gradient\n",
    "        \n",
    "        # Print log-likelihood every so often\n",
    "        if step % 10000 == 0:\n",
    "            print (LogLikelihoodBinomial(features, weights, target))\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-207.88100036898805\n",
      "-207.1121586666762\n",
      "-216.4784405494074\n",
      "-224.21619536591578\n",
      "-230.9462297790312\n",
      "-237.00596541777645\n",
      "-242.58493271648635\n",
      "-247.7989734684277\n",
      "-252.72403275283463\n",
      "-257.4126825330185\n",
      "-261.9028814642768\n",
      "-266.22295941661616\n",
      "-270.39462861051027\n",
      "-274.4348963763055\n",
      "-278.35733240660653\n",
      "-282.1729383064939\n",
      "-285.8907618588712\n",
      "-289.5183415100595\n",
      "-293.0620344562345\n",
      "-296.527262837107\n",
      "-299.91870104089\n",
      "-303.2404198765592\n",
      "-306.49599866115807\n",
      "-309.6886131265522\n",
      "-312.82110489963395\n",
      "-315.8960368067719\n",
      "-318.9157371825995\n",
      "-321.8823355880612\n",
      "-324.79779177337616\n",
      "-327.66391929844383\n"
     ]
    }
   ],
   "source": [
    "weights = gradient_est(X, Y,\n",
    "                     num_steps = 300000, learning_rate = 5e-5, add_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.43984032,  1.05121279, -1.57460734, -0.20419974,  2.65601601,\n",
       "       -2.42915583,  2.62162544, -3.71579454,  3.27595422, -4.42482985])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  1. , -1.5,  2. , -2.5,  3. , -3.5,  4. , -4.5]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Beta.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.93284793] [[  5.54930957  -9.00085504  -3.83806012  13.39360136 -11.74046102\n",
      "   23.20384225 -18.95686368  18.02401575 -22.54700936]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#let's see how sklearn does on our beta estimation\n",
    "\n",
    "clf = LogisticRegression(fit_intercept=True, C = 1e15)\n",
    "clf.fit(X, Y)\n",
    "\n",
    "print (clf.intercept_, clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
